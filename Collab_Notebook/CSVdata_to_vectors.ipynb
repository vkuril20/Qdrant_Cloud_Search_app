{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G21AgULnpcb2"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import nltk\n",
        "from qdrant_client import QdrantClient, models\n",
        "import re,os"
      ],
      "metadata": {
        "id": "r7NRffLfpsVb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "mZoUPlFep9RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cpu\")"
      ],
      "metadata": {
        "id": "vlkM6IIlqDcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product = pd.read_csv('/content/bigBasketProducts.csv')"
      ],
      "metadata": {
        "id": "NHDxrkVaqIrM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product.info()"
      ],
      "metadata": {
        "id": "X9x6SZMNrLt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rating column has some null entries filing those null entries with 0,\n",
        "description column also has null entries filing it to avoid error"
      ],
      "metadata": {
        "id": "Q1c0VLI3HV3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product['rating'] = product['rating'].fillna(0)\n",
        "\n",
        "# Next, handling missing values in all other columns\n",
        "# These are filled with \"NA\" to indicate data unavailability\n",
        "product = product.applymap(lambda x: \"NA\" if pd.isna(x) else x)\n",
        "\n",
        "# Converting all data types to string\n",
        "for column in product.columns:\n",
        "    product[column] = product[column].astype(str)\n",
        "\n",
        "# Display the DataFrame's structure and summary\n",
        "# This includes column data types, non-null counts, etc.\n",
        "print(product.info())"
      ],
      "metadata": {
        "id": "mdfuUs4JrPP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
        "    return text.lower()\n",
        "\n",
        "def filter_stopwords(text):\n",
        "    english_stopwords = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in text.split() if word.lower() not in english_stopwords]\n",
        "    return ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "CRlTgjeVrY1C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning our data to make efficient vector embeddings"
      ],
      "metadata": {
        "id": "09d3IfhsJNZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to apply both cleaning operations: removing characters/numbers and filtering stopwords\n",
        "def clean_and_filter_text(column_data):\n",
        "    cleaned_data = clean_text(column_data)\n",
        "    return filter_stopwords(cleaned_data)\n",
        "\n",
        "# Apply the 'clean_text' function to selected columns\n",
        "for column in ['product', 'category', 'sub_category', 'brand', 'type']:\n",
        "    product[column] = product[column].apply(clean_text)\n",
        "\n",
        "# For the 'description' column, apply both cleaning and filtering stopwords\n",
        "product['description'] = product['description'].apply(clean_and_filter_text)\n",
        "\n",
        "# Storing the modified DataFrame in 'original_df' for backup, comparison, or further processing purposes\n",
        "original_df = product"
      ],
      "metadata": {
        "id": "3OmCHgXRrwwT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving the processed data fro future use\n"
      ],
      "metadata": {
        "id": "zw2Y-vmZJbP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product.to_csv(\"/content/preprocessed_products.csv\",index = False)"
      ],
      "metadata": {
        "id": "tjgrhpavsU0_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "concatenating the columns to reduce the size of vector stores"
      ],
      "metadata": {
        "id": "4p3mmd4nJ-Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concated_text=[str(row.product) + \" \" + str(row.category) + \" \" + str(row.sub_category) + \" \" + str(row.type) + \" \" + str(row.brand) + \" \" + str(row.description)\n",
        "    for row in product.itertuples()]"
      ],
      "metadata": {
        "id": "TAX2QhnAKUZl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting the text into vector embeddings"
      ],
      "metadata": {
        "id": "GbXKJnCaLbwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_bigbasket = model.encode(concated_text, show_progress_bar=True,device='cpu')"
      ],
      "metadata": {
        "id": "JBZIdPeXshLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_bigbasket.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_BVLnc2Pyrw",
        "outputId": "41dbb78a-500f-452c-8da0-bdb7a893e1af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27555, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving the vector file as numpy array"
      ],
      "metadata": {
        "id": "znYBUKKsiEvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/vectors_bigbasket.npy', vectors_bigbasket, allow_pickle=False)"
      ],
      "metadata": {
        "id": "vfhHgLkSszEV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing a query search on the vectors to check the vectors"
      ],
      "metadata": {
        "id": "vqZZZcv9i-8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "gUHjj4srzcXC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_query1 = product.iloc[0].description\n",
        "sample_query2=product.iloc[441].description\n",
        "sample_query3=product.iloc[3211].description\n",
        "print(sample_query1)\n",
        "print(sample_query2)\n",
        "print(sample_query3)"
      ],
      "metadata": {
        "id": "K5cHDvnczjuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " check for any of the 3 query to verify the vectors embeddings"
      ],
      "metadata": {
        "id": "tUItfWO7k7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = model.encode(sample_query1,device='cpu')\n",
        "similarity_score = cosine_similarity([query], vectors_bigbasket)[0]\n",
        "\n",
        "# Retrieve the indices of the top 3 most similar items\n",
        "scores_id = np.argsort(similarity_score)[-3:][::-1]\n",
        "# Displaying the top 3 similar items\n",
        "for top_id in scores_id:\n",
        "  print(top_id)\n",
        "  print(product.iloc[top_id].description)\n",
        "  print(\"/n\")  # Ensuring a newline for better readability"
      ],
      "metadata": {
        "id": "HidQg5S7zm3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}